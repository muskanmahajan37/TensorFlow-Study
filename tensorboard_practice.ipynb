{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logic gate definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gate_and  = lambda x: x[0] and x[1]\n",
    "gate_or   = lambda x: x[0] or  x[1]\n",
    "gate_nand = lambda x: 1 - gate_and(x)\n",
    "gate_nor  = lambda x: 1 - gate_or(x)\n",
    "gate_xor  = lambda x: gate_and((gate_or(x), gate_nand(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gate_list = [('NAND', gate_nand), ('NOR', gate_nor), ('XOR', gate_xor)]\n",
    "\n",
    "x_list = np.array([[0., 0.], [0., 1.], [1., 0.], [1., 1.]]).astype(np.float32)\n",
    "y_list = {}\n",
    "\n",
    "for gate_name, gate_body in gate_list:        \n",
    "    y_list[gate_name] = np.array(map(gate_body, [(x[0], x[1]) for x in x_list])).reshape(4, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-task neural network design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x      = tf.placeholder(tf.float32, name='x')\n",
    "y_nand_true = tf.placeholder(tf.float32, name='y_nand')\n",
    "y_nor_true = tf.placeholder(tf.float32, name='y_nor')\n",
    "y_xor_true = tf.placeholder(tf.float32, name='y_xor')\n",
    "    \n",
    "with tf.name_scope('hidden_layer_1'):\n",
    "    h1_W      = tf.Variable(tf.random_uniform([2, 5], -1.0, 1.0))\n",
    "    h1_b      = tf.Variable(tf.zeros([5]))\n",
    "    h1        = tf.sigmoid(tf.matmul(x, h1_W) + h1_b)\n",
    "    \n",
    "with tf.name_scope('hidden_layer_2'):\n",
    "    h2_W      = tf.Variable(tf.random_uniform([5, 4], -1.0, 1.0))\n",
    "    h2_b      = tf.Variable(tf.zeros([4]))\n",
    "    h2        = tf.sigmoid(tf.matmul(h1, h2_W) + h2_b)\n",
    "    \n",
    "with tf.name_scope('nand_output'):\n",
    "    y_nand_W      = tf.Variable(tf.random_uniform([4, 1], -1.0, 1.0))\n",
    "    y_nand_b      = tf.Variable(tf.zeros([1]))\n",
    "    y_nand_pred   = tf.sigmoid(tf.matmul(h2, y_nand_W) + y_nand_b)\n",
    "    \n",
    "with tf.name_scope('nand_loss'):\n",
    "    loss_nand   = tf.reduce_mean(-y_nand_true * tf.log(y_nand_pred) - (1-y_nand_true) * tf.log(1-y_nand_pred), name='loss')\n",
    "    \n",
    "with tf.name_scope('nor_output'):\n",
    "    y_nor_W      = tf.Variable(tf.random_uniform([4, 1], -1.0, 1.0), name='weights')\n",
    "    y_nor_b      = tf.Variable(tf.zeros([1]), name='biases')\n",
    "    y_nor_pred   = tf.sigmoid(tf.matmul(h2, y_nor_W) + y_nor_b, name='y_pred')\n",
    "    \n",
    "with tf.name_scope('nor_loss'):\n",
    "    loss_nor   = tf.reduce_mean(-y_nor_true * tf.log(y_nor_pred) - (1-y_nor_true) * tf.log(1-y_nor_pred), name='loss')\n",
    "    \n",
    "with tf.name_scope('xor_output'):\n",
    "    y_xor_W      = tf.Variable(tf.random_uniform([4, 1], -1.0, 1.0), name='weights')\n",
    "    y_xor_b      = tf.Variable(tf.zeros([1]), name='biases')\n",
    "    y_xor_pred   = tf.sigmoid(tf.matmul(h2, y_xor_W) + y_xor_b, name='y_pred')\n",
    "    \n",
    "with tf.name_scope('xor_loss'):\n",
    "    loss_xor   = tf.reduce_mean(-y_xor_true * tf.log(y_xor_pred) - (1-y_xor_true) * tf.log(1-y_xor_pred), name='loss')\n",
    "    \n",
    "with tf.name_scope('joint_loss'):\n",
    "    loss_total = loss_nand + loss_nor + loss_xor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'joint_loss_trace:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.summary.scalar('nand_loss_trace', loss_nand)\n",
    "tf.summary.scalar('nor_loss_trace', loss_nor)\n",
    "tf.summary.scalar('xor_loss_trace', loss_xor)\n",
    "tf.summary.scalar('joint_loss_trace', loss_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feed_dict={\n",
    "    x:      np.concatenate([x_list for _ in range(10)]),\n",
    "    y_nand_true: np.concatenate([y_list['NAND'] for _ in range(10)]),\n",
    "    y_nor_true:  np.concatenate([y_list['NOR']  for _ in range(10)]),\n",
    "    y_xor_true:  np.concatenate([y_list['XOR']  for _ in range(10)])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    tb = tf.summary.FileWriter('./myboard/logic_gate', sess.graph)\n",
    "    tb_merged = tf.summary.merge_all()\n",
    "    \n",
    "    train_op = tf.train.AdamOptimizer(tf.Variable(0.01)).minimize(loss_total)\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in xrange(1000):\n",
    "        summary, _ = sess.run([tb_merged, train_op], feed_dict)\n",
    "        tb.add_summary(summary, i)\n",
    "        \n",
    "    tb.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
