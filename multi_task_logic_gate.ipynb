{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logic gate definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gate_and  = lambda x: x[0] and x[1]\n",
    "gate_or   = lambda x: x[0] or  x[1]\n",
    "gate_nand = lambda x: 1 - gate_and(x)\n",
    "gate_nor  = lambda x: 1 - gate_or(x)\n",
    "gate_xor  = lambda x: gate_and((gate_or(x), gate_nand(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gate_list = [('AND', gate_and), ('OR', gate_or), ('NAND', gate_nand), ('NOR', gate_nor), ('XOR', gate_xor)]\n",
    "x_list = np.array([[0., 0.], [0., 1.], [1., 0.], [1., 1.]]).astype(np.float32)\n",
    "y_list = {}\n",
    "\n",
    "for gate_name, gate_body in gate_list:        \n",
    "    y_list[gate_name] = np.array(map(gate_body, [(x[0], x[1]) for x in x_list])).reshape(4, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-task neural network design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'h1_W':     tf.Variable(tf.random_uniform([2, 5], -1.0, 1.0)),\n",
    "    'h2_W':     tf.Variable(tf.random_uniform([5, 4], -1.0, 1.0)),\n",
    "    'y_and_W':  tf.Variable(tf.random_uniform([4, 1], -1.0, 1.0)),\n",
    "    'y_or_W':   tf.Variable(tf.random_uniform([4, 1], -1.0, 1.0)),\n",
    "    'y_nand_W': tf.Variable(tf.random_uniform([4, 1], -1.0, 1.0)),\n",
    "    'y_nor_W':  tf.Variable(tf.random_uniform([4, 1], -1.0, 1.0)),\n",
    "    'y_xor_W':  tf.Variable(tf.random_uniform([4, 1], -1.0, 1.0))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'h1_b':     tf.Variable(tf.zeros([5])),\n",
    "    'h2_b':     tf.Variable(tf.zeros([4])),\n",
    "    'y_and_b':  tf.Variable(tf.zeros([1])),\n",
    "    'y_or_b':   tf.Variable(tf.zeros([1])),\n",
    "    'y_nand_b': tf.Variable(tf.zeros([1])),\n",
    "    'y_nor_b':  tf.Variable(tf.zeros([1])),\n",
    "    'y_xor_b':  tf.Variable(tf.zeros([1]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32)\n",
    "\n",
    "h1 = tf.sigmoid(tf.matmul(x, weights['h1_W']) + biases['h1_b'])\n",
    "\n",
    "h2 = tf.sigmoid(tf.matmul(h1, weights['h2_W']) + biases['h2_b'])\n",
    "\n",
    "y_and_pred  = tf.sigmoid(tf.matmul(h2, weights['y_and_W'])  + biases['y_and_b'])\n",
    "y_or_pred   = tf.sigmoid(tf.matmul(h2, weights['y_or_W'])   + biases['y_or_b'])\n",
    "y_nand_pred = tf.sigmoid(tf.matmul(h2, weights['y_nand_W']) + biases['y_nand_b'])\n",
    "y_nor_pred  = tf.sigmoid(tf.matmul(h2, weights['y_nor_W'])  + biases['y_nor_b'])\n",
    "y_xor_pred  = tf.sigmoid(tf.matmul(h2, weights['y_xor_W'])  + biases['y_xor_b'])\n",
    "\n",
    "y_and_true  = tf.placeholder(tf.float32)\n",
    "y_or_true   = tf.placeholder(tf.float32)\n",
    "y_nand_true = tf.placeholder(tf.float32)\n",
    "y_nor_true  = tf.placeholder(tf.float32)\n",
    "y_xor_true  = tf.placeholder(tf.float32)\n",
    "\n",
    "loss_and   = tf.reduce_mean(-y_and_true  * tf.log(y_and_pred)  - (1-y_and_true)  * tf.log(1-y_and_pred))\n",
    "loss_or    = tf.reduce_mean(-y_or_true   * tf.log(y_or_pred)   - (1-y_or_true)   * tf.log(1-y_or_pred))\n",
    "loss_nand  = tf.reduce_mean(-y_nand_true * tf.log(y_nand_pred) - (1-y_nand_true) * tf.log(1-y_nand_pred))\n",
    "loss_nor   = tf.reduce_mean(-y_nor_true  * tf.log(y_nor_pred)  - (1-y_nor_true)  * tf.log(1-y_nor_pred))\n",
    "loss_xor   = tf.reduce_mean(-y_xor_true  * tf.log(y_xor_pred)  - (1-y_xor_true)  * tf.log(1-y_xor_pred))\n",
    "loss_total = loss_and + loss_or + loss_nand + loss_nor + loss_xor\n",
    "\n",
    "correct_xor  = tf.equal(tf.equal(y_xor_true, 1.0), tf.greater(y_xor_pred, 0.5))\n",
    "accuracy_xor = tf.reduce_mean(tf.cast(correct_xor, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = {\n",
    "    x:           np.concatenate([x_list         for _ in range(10)]),\n",
    "    y_and_true:  np.concatenate([y_list['AND']  for _ in range(10)]),\n",
    "    y_or_true:   np.concatenate([y_list['OR']   for _ in range(10)]),\n",
    "    y_nand_true: np.concatenate([y_list['NAND'] for _ in range(10)]),\n",
    "    y_nor_true:  np.concatenate([y_list['NOR']  for _ in range(10)]),\n",
    "    y_xor_true:  np.concatenate([y_list['XOR']  for _ in range(10)])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data = {\n",
    "    x:x_list,\n",
    "    y_and_true: y_list['AND'],\n",
    "    y_or_true:  y_list['OR'],\n",
    "    y_nand_true:y_list['NAND'],\n",
    "    y_nor_true: y_list['NOR'],\n",
    "    y_xor_true: y_list['XOR']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_loss(sess, iter):\n",
    "    print('%d %f %f %f %f %f'%(\n",
    "        iter,\n",
    "        sess.run(loss_and, train_data),\n",
    "        sess.run(loss_or, train_data),\n",
    "        sess.run(loss_nand, train_data),\n",
    "        sess.run(loss_nor, train_data),\n",
    "        sess.run(loss_xor, train_data)))\n",
    "    \n",
    "def dnn_experiment(train_op_list):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        num_iter = 1000\n",
    "        for i in range(num_iter):\n",
    "            sess.run(random.sample(train_op_list, 1), train_data)\n",
    "            if accuracy_xor.eval(test_data) == 1.0:\n",
    "                print_loss(sess, i+1)\n",
    "                return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_op_and   = tf.train.AdamOptimizer(tf.Variable(0.1)).minimize(loss_and)\n",
    "train_op_or    = tf.train.AdamOptimizer(tf.Variable(0.1)).minimize(loss_or)\n",
    "train_op_nand  = tf.train.AdamOptimizer(tf.Variable(0.1)).minimize(loss_nand)\n",
    "train_op_nor   = tf.train.AdamOptimizer(tf.Variable(0.1)).minimize(loss_nor)\n",
    "train_op_xor   = tf.train.AdamOptimizer(tf.Variable(0.1)).minimize(loss_xor)\n",
    "train_op_total = tf.train.AdamOptimizer(tf.Variable(0.1)).minimize(loss_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XOR only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 0.773797 1.001325 0.738363 0.597698 0.386693\n"
     ]
    }
   ],
   "source": [
    "dnn_experiment([train_op_xor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternate MTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295 0.082623 0.090572 0.072079 0.044362 0.414339\n"
     ]
    }
   ],
   "source": [
    "dnn_experiment([train_op_and, train_op_or, train_op_nand, train_op_nor, train_op_xor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint MTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 0.039241 0.033578 0.053141 0.047369 0.455856\n"
     ]
    }
   ],
   "source": [
    "dnn_experiment([train_op_total])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
